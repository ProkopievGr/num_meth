{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple iteration for systems of linear equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, generate a random diagonally dominant matrix, for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rndm = np.random.RandomState(1234)\n",
    "\n",
    "n = 10\n",
    "A = rndm.uniform(size=(n, n)) + np.diagflat([15]*n)\n",
    "b = rndm.uniform(size=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I.  Jacobi iteration\n",
    "\n",
    "Given\n",
    "\n",
    "$$\n",
    "A x = b\n",
    "$$\n",
    "\n",
    "separate the diagonal part $D$,\n",
    "\n",
    "$$ A = D + (A - D) $$\n",
    "\n",
    "and write\n",
    "\n",
    "$$\n",
    "x = D^{-1} (D - A) x + D^{-1} b\\;.\n",
    "$$\n",
    "\n",
    "Then iterate\n",
    "\n",
    "$$\n",
    "x_{n + 1} = B x_{n} + c\\;,\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "B = D^{-1} (A - D) \\qquad \\text{and} \\qquad c = D^{-1} b\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct the matrix and the r.h.s. for the Jacobi iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_1d = np.diag(A)\n",
    "\n",
    "B = -A.copy()\n",
    "np.fill_diagonal(B, 0)\n",
    "\n",
    "D = np.diag(diag_1d)\n",
    "invD = np.diag(1./diag_1d)\n",
    "BB = invD @ B \n",
    "c = invD @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "assert_allclose(-B + D, A)\n",
    "\n",
    "\n",
    "# xx is a \"ground truth\" solution, compute it using a direct method\n",
    "xx = np.linalg.solve(A, b)\n",
    "\n",
    "np.testing.assert_allclose(A@xx, b)\n",
    "np.testing.assert_allclose(D@xx, B@xx + b)\n",
    "np.testing.assert_allclose(xx, BB@xx + c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that $\\| B\\| \\leqslant 1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36436161983015336"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(BB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the Jacobi iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 50\n",
    "\n",
    "x0 = np.ones(n)\n",
    "x = x0\n",
    "for _ in range(n_iter):\n",
    "    x = BB @ x + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.11022302e-16,  0.00000000e+00, -2.22044605e-16, -1.11022302e-16,\n",
       "        1.11022302e-16,  0.00000000e+00, -2.08166817e-17,  0.00000000e+00,\n",
       "       -2.77555756e-17,  1.11022302e-16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the result:\n",
    "\n",
    "A @ x - b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task I.1\n",
    "\n",
    "Collect the proof-of-concept above into a single function implementing the Jacobi iteration. This function should receive the r.h.s. matrix $A$, the l.h.s. vector `b`, and the number of iterations to perform.\n",
    "\n",
    "\n",
    "The matrix $A$ in the illustration above is strongly diagonally dominant, by construction. \n",
    "What happens if the diagonal matrix elements of $A$ are made smaller? Check the convergence of the Jacobi iteration, and check the value of the norm of $B$.\n",
    "\n",
    "(20% of the total grade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... ENTER YOUR CODE HERE ...\n",
    "def Jacobi_iteration(A, b, num_iter=50, verbose=False):\n",
    "    B = -A.copy()\n",
    "    np.fill_diagonal(B, 0)\n",
    "    \n",
    "    diag = np.diag(A)\n",
    "    inv_diag = np.diag(1./diag)\n",
    "    B = np.dot(inv_diag, B)\n",
    "    c = np.dot(inv_diag, b)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"norm B:\", np.linalg.norm(B, ord=np.inf))\n",
    "        \n",
    "    x_new = np.ones_like(b)\n",
    "    for i in range(num_iter):\n",
    "        x_prev = x_new.copy()\n",
    "        x_new = np.dot(B, x_prev) + c\n",
    "        if verbose:\n",
    "            print(\"%d:\" % i, np.linalg.norm(x_new - x_prev))\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Jacobi_iteration(A, b)\n",
    "xx = np.linalg.solve(A, b)\n",
    "\n",
    "np.allclose(x, xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check convergense of Jacobi method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm B: 0.3969558732098327\n",
      "0: 4.017670932150149\n",
      "1: 1.2439262407070686\n",
      "2: 0.37150589709834797\n",
      "3: 0.11149610276038871\n",
      "4: 0.033437377185133677\n",
      "5: 0.01002777263094849\n",
      "6: 0.0030074056173186965\n",
      "7: 0.0009019337306094896\n",
      "8: 0.0002704944221843025\n",
      "9: 8.112259066743358e-05\n",
      "10: 2.432906062204276e-05\n",
      "11: 7.2964038372576306e-06\n",
      "12: 2.1882270753681245e-06\n",
      "13: 6.562599651808278e-07\n",
      "14: 1.9681556216645286e-07\n",
      "15: 5.902594636795646e-08\n",
      "16: 1.770216900721955e-08\n",
      "17: 5.3089667635383426e-09\n",
      "18: 1.5921850085505798e-09\n",
      "19: 4.775040495842271e-10\n",
      "20: 1.4320579748219748e-10\n",
      "21: 4.294811884741762e-11\n",
      "22: 1.2880351114952751e-11\n",
      "23: 3.86287896476393e-12\n",
      "24: 1.1584939050400663e-12\n",
      "25: 3.474423252972769e-13\n",
      "26: 1.0420575239324089e-13\n",
      "27: 3.125362897997318e-14\n",
      "28: 9.370374086345794e-15\n",
      "29: 2.80638747251276e-15\n",
      "30: 8.42665475904218e-16\n",
      "31: 2.515543441319542e-16\n",
      "32: 7.238184373059934e-17\n",
      "33: 1.9778890766513102e-17\n",
      "34: 8.673617379884035e-18\n",
      "35: 3.469446951953614e-18\n",
      "36: 0.0\n",
      "37: 0.0\n",
      "38: 0.0\n",
      "39: 0.0\n",
      "40: 0.0\n",
      "41: 0.0\n",
      "42: 0.0\n",
      "43: 0.0\n",
      "44: 0.0\n",
      "45: 0.0\n",
      "46: 0.0\n",
      "47: 0.0\n",
      "48: 0.0\n",
      "49: 0.0\n"
     ]
    }
   ],
   "source": [
    "x = Jacobi_iteration(A, b, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look what happens if matrix A is not diagonally dominant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm B: 16.78389594884626\n",
      "0: 30.614999981715687\n",
      "1: 260.14453080221784\n",
      "2: 2241.7051872050074\n",
      "3: 19271.37004107396\n",
      "4: 165572.18421145683\n",
      "5: 1423137.192151448\n",
      "6: 12230378.049585639\n",
      "7: 105111360.60152042\n",
      "8: 903350809.7034506\n",
      "9: 7763606477.923543\n",
      "10: 66722240220.17173\n",
      "11: 573426428152.5233\n",
      "12: 4928159939361.045\n",
      "13: 42353751442368.37\n",
      "14: 363997979201504.2\n",
      "15: 3128283196103139.5\n",
      "16: 2.688519253610676e+16\n",
      "17: 2.3105759051097872e+17\n",
      "18: 1.9857626111744604e+18\n",
      "19: 1.7066105204424956e+19\n",
      "20: 1.4667007285237663e+20\n",
      "21: 1.260516679865771e+21\n",
      "22: 1.0833173184682614e+22\n",
      "23: 9.310280706624536e+22\n",
      "24: 8.001471531785953e+23\n",
      "25: 6.876650521227191e+24\n",
      "26: 5.9099532133859e+25\n",
      "27: 5.079151089123144e+26\n",
      "28: 4.365140442687345e+27\n",
      "29: 3.751503105546363e+28\n",
      "30: 3.224128922243716e+29\n",
      "31: 2.7708912973789246e+30\n",
      "32: 2.381368353144869e+31\n",
      "33: 2.0466032856374438e+32\n",
      "34: 1.7588984095007708e+33\n",
      "35: 1.5116381551106307e+34\n",
      "36: 1.299136948241848e+35\n",
      "37: 1.1165084743204446e+36\n",
      "38: 9.595533210847459e+36\n",
      "39: 8.24662416078095e+37\n",
      "40: 7.087340385867924e+38\n",
      "41: 6.091024977716179e+39\n",
      "42: 5.234768369971411e+40\n",
      "43: 4.49888154908335e+41\n",
      "44: 3.866443319400041e+42\n",
      "45: 3.3229112122721147e+43\n",
      "46: 2.8557870922978108e+44\n",
      "47: 2.4543297715614445e+45\n",
      "48: 2.1093080236335348e+46\n",
      "49: 1.8127883180646256e+47\n"
     ]
    }
   ],
   "source": [
    "A1 = rndm.uniform(size=(n, n))\n",
    "x1 = Jacobi_iteration(A1, b, verbose=True)\n",
    "xx1 = np.linalg.solve(A1, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.71472847e+46, -2.19650221e+46, -2.70898688e+46, -3.44764908e+46,\n",
       "       -4.31425974e+46, -4.17765861e+46, -7.64567150e+46, -3.15125314e+46,\n",
       "       -3.31634010e+46, -8.04173396e+46])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = xx1 - x1\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, difference between iterations grows and it does not converge to the true answer, since the norm of B is far bigger than 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Seidel's iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task II.1\n",
    "\n",
    "Implement the Seidel's iteration. \n",
    "\n",
    "Test it on a random matrix. Study the convergence of iterations, relate to the norm of the iteration matrix.\n",
    "\n",
    "(30% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... ENTER YOUR CODE HERE ...\n",
    "def Seidel_iteration(A, b, num_iter=50, verbose=False, verbose_B=False):\n",
    "    B = -A.copy()\n",
    "    np.fill_diagonal(B, 0)\n",
    "    B = np.dot(np.diag(1./np.diag(A)), B)\n",
    "    \n",
    "    if verbose_B:\n",
    "        print(\"norm B:\", np.linalg.norm(B, ord=np.inf))\n",
    "    \n",
    "    x_new = np.ones_like(b)\n",
    "    for i in range(num_iter):\n",
    "        x_prev = x_new.copy()\n",
    "        for j in range(len(b)):\n",
    "            x_new[j] = (b[j] - np.dot(A[j, j+1:], x_prev[j+1:]) - np.dot(A[j, :j], x_prev[:j]))/A[j, j]\n",
    "            \n",
    "        if verbose:\n",
    "            print(np.linalg.norm(x_new - x_prev))\n",
    "        \n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = rndm.uniform(size=(n, n)) + np.diagflat([15]*n)\n",
    "b = rndm.uniform(size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm B: 0.3742909530999712\n"
     ]
    }
   ],
   "source": [
    "x = Seidel_iteration(A, b, verbose_B=True)\n",
    "xx = np.linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(x, xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(np.dot(A, x), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Minimum residual scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task III.1\n",
    "\n",
    "Implement the $\\textit{minimum residual}$ scheme: an explicit non-stationary method, where at each step you select the iteration parameter $\\tau_n$ to minimize the residual $\\mathbf{r}_{n+1}$ given $\\mathbf{r}_n$. Test it on a random matrix, study the convergence to the solution, in terms of the norm of the residual and the deviation from the ground truth solution (which you can obtain using a direct method). Study how the iteration parameter $\\tau_n$ changes as iterations progress.\n",
    "\n",
    "(50% of the grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... ENTER YOUR CODE HERE ...\n",
    "def min_res_iteration(A, b, ground_trurh=None, eps=1e-8, num_iter=50, verbose=False, early_break=False):\n",
    "    x_new = np.ones_like(b)\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        x_prev = x_new.copy()\n",
    "        \n",
    "        residual = np.dot(A, x_prev) - b\n",
    "        A_res = np.dot(A, residual)\n",
    "        tau = np.dot(residual, A_res)/np.dot(A_res, A_res)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"%d:\" %i, \"residual norm: %f\" % np.linalg.norm(residual), \"tau: %f\" % tau)\n",
    "            if ground_trurh is not None:\n",
    "                print(\"deviation: %.8f\" % np.linalg.norm(ground_trurh - x_prev))\n",
    "            print(\"----------------------------------\")\n",
    "        \n",
    "        x_new = x_prev - tau*residual\n",
    "        \n",
    "        if early_break:\n",
    "            if np.linalg.norm(x_new - x_prev) < eps:\n",
    "                print(\"early break at %d iteration\" % i)\n",
    "                break\n",
    "        \n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2 = rndm.uniform(size=(n, n)) + np.diagflat([15]*n)\n",
    "b2 = rndm.uniform(size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = min_res_iteration(A2, b2)\n",
    "xx2 = np.linalg.solve(A2, b2)\n",
    "\n",
    "np.allclose(x2, xx2, atol=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: residual norm: 62.526919 tau: 0.048929\n",
      "deviation: 3.05841903\n",
      "----------------------------------\n",
      "1: residual norm: 1.530105 tau: 0.066696\n",
      "deviation: 0.10320236\n",
      "----------------------------------\n",
      "2: residual norm: 0.137148 tau: 0.054084\n",
      "deviation: 0.00781558\n",
      "----------------------------------\n",
      "3: residual norm: 0.018842 tau: 0.059218\n",
      "deviation: 0.00118823\n",
      "----------------------------------\n",
      "4: residual norm: 0.003160 tau: 0.056548\n",
      "deviation: 0.00019174\n",
      "----------------------------------\n",
      "5: residual norm: 0.000513 tau: 0.058791\n",
      "deviation: 0.00003265\n",
      "----------------------------------\n",
      "6: residual norm: 0.000096 tau: 0.057094\n",
      "deviation: 0.00000590\n",
      "----------------------------------\n",
      "7: residual norm: 0.000016 tau: 0.058203\n",
      "deviation: 0.00000099\n",
      "----------------------------------\n",
      "8: residual norm: 0.000003 tau: 0.057532\n",
      "deviation: 0.00000018\n",
      "----------------------------------\n",
      "9: residual norm: 0.000000 tau: 0.057636\n",
      "deviation: 0.00000003\n",
      "----------------------------------\n",
      "10: residual norm: 0.000000 tau: 0.058035\n",
      "deviation: 0.00000001\n",
      "----------------------------------\n",
      "11: residual norm: 0.000000 tau: 0.057027\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "12: residual norm: 0.000000 tau: 0.058652\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "13: residual norm: 0.000000 tau: 0.056365\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "14: residual norm: 0.000000 tau: 0.059397\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "15: residual norm: 0.000000 tau: 0.055676\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "16: residual norm: 0.000000 tau: 0.060236\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "17: residual norm: 0.000000 tau: 0.055029\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "18: residual norm: 0.000000 tau: 0.061058\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "19: residual norm: 0.000000 tau: 0.054430\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "20: residual norm: 0.000000 tau: 0.061616\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "21: residual norm: 0.000000 tau: 0.054381\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "22: residual norm: 0.000000 tau: 0.054889\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "23: residual norm: 0.000000 tau: 0.058272\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "24: residual norm: 0.000000 tau: 0.062652\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "25: residual norm: 0.000000 tau: 0.062015\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "26: residual norm: 0.000000 tau: 0.062652\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "27: residual norm: 0.000000 tau: 0.062015\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "28: residual norm: 0.000000 tau: 0.062652\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "29: residual norm: 0.000000 tau: 0.062015\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "30: residual norm: 0.000000 tau: 0.062652\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "31: residual norm: 0.000000 tau: 0.062015\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "32: residual norm: 0.000000 tau: 0.062652\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "33: residual norm: 0.000000 tau: 0.062015\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "34: residual norm: 0.000000 tau: 0.062652\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "35: residual norm: 0.000000 tau: 0.062015\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "36: residual norm: 0.000000 tau: 0.062652\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "37: residual norm: 0.000000 tau: 0.062015\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "38: residual norm: 0.000000 tau: 0.062652\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "39: residual norm: 0.000000 tau: 0.062015\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "40: residual norm: 0.000000 tau: 0.062652\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "41: residual norm: 0.000000 tau: 0.062015\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "42: residual norm: 0.000000 tau: 0.062652\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "43: residual norm: 0.000000 tau: 0.062015\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "44: residual norm: 0.000000 tau: 0.062652\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "45: residual norm: 0.000000 tau: 0.062015\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "46: residual norm: 0.000000 tau: 0.062652\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "47: residual norm: 0.000000 tau: 0.062015\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "48: residual norm: 0.000000 tau: 0.062652\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n",
      "49: residual norm: 0.000000 tau: 0.062015\n",
      "deviation: 0.00000000\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.02331187,  0.04463403,  0.0494192 ,  0.03055605,  0.0485216 ,\n",
       "        0.03657139, -0.00903743,  0.04390046,  0.01372572,  0.04851064])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_res_iteration(A2, b2, ground_trurh=xx2, verbose=True, early_break=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, norm of the residual converges to zero as iteration progress. As for tau, it grows firstly, then remains almost still, since iterations get quite close to the true solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
