{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. One-sided finite differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, `deriv`, which computes a derivative of its argument at a given point, $x$, using a one-sided finite difference rule with a given step side $h$, with the approximation order of $O(h^2)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv(f, x, h):\n",
    "    \"\"\" Compute a derivative of `f` at point `x` with step size `h`.\n",
    "    \n",
    "    Compute the derivative using the one-sided rule of the approximation order of $O(h^2)$.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f : callable\n",
    "        The function to differentiate\n",
    "    x : float\n",
    "        The point to compute the derivative at.\n",
    "    h : float\n",
    "        The step size for the finite different rule.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    fder : derivative of f(x) at point x using the step size h.\n",
    "    \"\"\"\n",
    "    return (-1.5*f(x) + 2*f(x+h) - 1/2*f(x+2*h))/h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test I.1\n",
    "\n",
    "Test your function on a simple test case: differentiate $f(x) = x^3$ at $x=0$. Comment on whether your results are consistent with the expected value of $f'(x) = 0$ and on an expected scaling with $h\\to 0$.\n",
    "\n",
    " (10% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010000 -- -0.0002\n",
      "0.001000 --  -2e-06\n",
      "0.000100 --  -2e-08\n",
      "0.000010 --  -2e-10\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for h in [1e-2, 1e-3, 1e-4, 1e-5]:\n",
    "    err = deriv(lambda x: x**3, x, h)\n",
    "    print(\"%5f -- %7.4g\" % (h, err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error is $O(h^2)$.\\\n",
    "For a scheme with the approxiamtion order of $O(h^2)$ the optimal step $h$ is about $(10^{-16})^{1/3} > 10^{-5}$. The results are consistent with that: the error is the smallest when $h = 10^{-5}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test I.2\n",
    "\n",
    "Now use a slightly more complicated function, $f(x) = x^2 \\log{x}$, evaluate the derivative at $x=1$ using your one-sided rule and a two-point one-sided rule. Roughly estimate the value of $h$ where the error stops decreasing, for these two schemes. \n",
    "(15% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def f(x):\n",
    "    return x**2 * log(x)\n",
    "    \n",
    "def fder(x):\n",
    "    return x * (2.*log(x) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_p_1_sided(f, x, h):\n",
    "    return (f(x+h) - f(x))/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h: 0.1 -- 2 point 1-sided err:  0.1533 -- my 1-sided 0.006209\n",
      "h: 0.01 -- 2 point 1-sided err: 0.01503 -- my 1-sided 6.617e-05\n",
      "h: 0.001 -- 2 point 1-sided err:  0.0015 -- my 1-sided 6.662e-07\n",
      "h: 0.0001 -- 2 point 1-sided err: 0.00015 -- my 1-sided 6.666e-09\n",
      "h: 1e-05 -- 2 point 1-sided err: 1.5e-05 -- my 1-sided 4.901e-11\n",
      "h: 1e-06 -- 2 point 1-sided err: 1.5e-06 -- my 1-sided 1.94e-10\n",
      "h: 1e-07 -- 2 point 1-sided err: 1.506e-07 -- my 1-sided 1.694e-09\n",
      "h: 1e-08 -- 2 point 1-sided err: 8.923e-09 -- my 1-sided 1.718e-08\n",
      "h: 1e-09 -- 2 point 1-sided err: 8.424e-08 -- my 1-sided 1.938e-07\n",
      "h: 1e-10 -- 2 point 1-sided err: 8.289e-08 -- my 1-sided 8.274e-08\n"
     ]
    }
   ],
   "source": [
    "x = 1\n",
    "h_list = [pow(10, -i) for i in range(1, 11)]\n",
    "\n",
    "for h in h_list:\n",
    "    a = abs(fder(x) - two_p_1_sided(f, x, h))\n",
    "    b = abs(fder(x) - deriv(f, x, h))\n",
    "    print(\"h: %.4g -- 2 point 1-sided err: %7.4g -- my 1-sided %.4g\" % (h, a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error stops decreasing at roughly $h = 10^{-8}$ for 2-point 1-sided method and at $h = 10^{-5}$ for 3-points 1-sided scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test I.3 \n",
    "\n",
    "Now try differentiating $x^2 \\log(x)$ at $x=0$. Use the three-point one-sided rule. Note that to evaluate the function at zero, you need to special-case this value. Check the scaling of the error with $h$, explain your results. \n",
    "(25% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010000 -- -0.01386\n",
      "0.001000 -- -0.001386\n",
      "0.000100 -- -0.0001386\n",
      "0.000010 -- -1.386e-05\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    if x == 0:\n",
    "        # the limit of $x^2 log(x)$ at $x-> 0$ is zero, even though log(x) is undefined at x=0\n",
    "        return 0.0\n",
    "    else:\n",
    "        return x**2 * log(x)\n",
    "    \n",
    "def fder(x):\n",
    "    if x == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return x*(2*log(x) + 1)\n",
    "\n",
    "x = 0\n",
    "for h in [1e-2, 1e-3, 1e-4, 1e-5]:\n",
    "    err = deriv(f, x, h) - fder(x)\n",
    "    print(\"%5f -- %7.4g\" % (h, err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the error is $O(h^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Midpoint rule "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which computes a definite integral using the midpoint rule up to a given error, $\\epsilon$. Estimate the error by comparing the estimates of the integral at $N$ and $2N$ elementary intervals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint_rule(func, a, b, eps):\n",
    "    \"\"\" Calculate the integral of f from a to b using the midpoint rule.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "        The function to integrate.\n",
    "    a : float\n",
    "        The lower limit of integration.\n",
    "    b : float\n",
    "        The upper limit of integration.\n",
    "    eps : float\n",
    "        The target accuracy of the estimate.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    integral : float\n",
    "        The estimate of $\\int_a^b f(x) dx$.\n",
    "    \"\"\"\n",
    "    def quadr_sum(f, a, b, N):\n",
    "        x = np.linspace(a, b, N)\n",
    "        mid_points = (x[1:] + x[:-1])/2\n",
    "        return np.sum(f(mid_points))*(x[1] - x[0])\n",
    "    \n",
    "    N = 5\n",
    "    I_n = quadr_sum(func, a, b, N)\n",
    "    I_2n = eps*10\n",
    "    while abs(I_2n - I_n) > eps and N < 1e5:\n",
    "        I_n = I_2n\n",
    "        N *= 2\n",
    "        I_2n = quadr_sum(func, a, b, N)\n",
    "        print(\"Intervals: {}, Error: {}\".format(N, abs(I_2n - I_n)))\n",
    "        \n",
    "    return I_2n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test II.1\n",
    "\n",
    "Test your midpoint rule on a simple integral, which you can calculate by paper and pencil.\n",
    "\n",
    "Compare the rate of convergence to the expected $O(N^{-2})$ scaling by studying the number of intervals required for a given accuracy $\\epsilon$.\n",
    "\n",
    "Compare the numerical results to the value you calculated by hand. Does the deviation agree with your estimate of the numerical error?\n",
    "(20% of the total grade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervals: 10, Error: 0.3323035267489712\n",
      "Intervals: 20, Error: 0.0007979663258210201\n",
      "Intervals: 40, Error: 0.0001760517422141894\n",
      "Intervals: 80, Error: 4.14359553057575e-05\n",
      "Intervals: 160, Error: 1.005627791006436e-05\n",
      "Intervals: 320, Error: 2.477370823206204e-06\n",
      "Intervals: 640, Error: 6.148244909853773e-07\n",
      "Intervals: 1280, Error: 1.5314560064538796e-07\n",
      "Intervals: 2560, Error: 3.821659888547657e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2725597409168898e-08"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/3 - midpoint_rule(f, 0, 1, eps=1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test II.2\n",
    "\n",
    "Now use your midpoint rule to compute the value of\n",
    "\n",
    "$$\n",
    "\\int_0^1\\! \\frac{\\sin{\\sqrt{x}}}{x}\\, dx\n",
    "$$\n",
    "\n",
    "up to a predefined accuracy of $\\epsilon=10^{-4}$.\n",
    "\n",
    "Note that the integral contains an integrable singularity at the lower limit. Do calculations two ways: first, do a straightforward computation; next, subtract the singularity. Compare the number of iterations required to achieve the accuracy of $\\epsilon$.\n",
    "\n",
    "(30% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda x: np.sin(np.sqrt(x))/x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervals: 10, Error: 1.6894515015604419\n",
      "Intervals: 20, Error: 0.06288485091200768\n",
      "Intervals: 40, Error: 0.04194248308726989\n",
      "Intervals: 80, Error: 0.02882025487535289\n",
      "Intervals: 160, Error: 0.020091347902667644\n",
      "Intervals: 320, Error: 0.014106333229680024\n",
      "Intervals: 640, Error: 0.009939378727305659\n",
      "Intervals: 1280, Error: 0.007015743719722689\n",
      "Intervals: 2560, Error: 0.0049564770796921565\n",
      "Intervals: 5120, Error: 0.003503201622899077\n",
      "Intervals: 10240, Error: 0.002476586965677763\n",
      "Intervals: 20480, Error: 0.0017510166777789937\n",
      "Intervals: 40960, Error: 0.0012380868865000672\n",
      "Intervals: 81920, Error: 0.0008754352739643867\n",
      "Intervals: 163840, Error: 0.0006190176047349283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.8906717161256956"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midpoint_rule(g, 0, 1, 1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
